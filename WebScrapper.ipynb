{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScrapper.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debanga/Random-Colabs/blob/master/WebScrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pqUT4uhut1JX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" Web scraping example\n",
        "    @author Debanga Raj Neog\n",
        "    based on: https://www.digitalocean.com/community/tutorials/how-to-crawl-a-web-page-with-scrapy-and-python-3\n",
        "\"\"\"\n",
        "!pip install scrapy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzH3RsquvG8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "\n",
        "class BrickSetSpider(scrapy.Spider):\n",
        "    name = 'brick_spider'\n",
        "    start_urls = ['http://brickset.com/sets/year-2016']\n",
        "\n",
        "    def parse(self, response):\n",
        "        SET_SELECTOR = '.set'\n",
        "        for brickset in response.css(SET_SELECTOR):\n",
        "\n",
        "            NAME_SELECTOR = 'h1 ::text'\n",
        "            PIECES_SELECTOR = './/dl[dt/text() = \"Pieces\"]/dd/a/text()'\n",
        "            MINIFIGS_SELECTOR = './/dl[dt/text() = \"Minifigs\"]/dd[2]/a/text()'\n",
        "            IMAGE_SELECTOR = 'img ::attr(src)'\n",
        "            yield {\n",
        "                'name': brickset.css(NAME_SELECTOR).extract_first(),\n",
        "                'pieces': brickset.xpath(PIECES_SELECTOR).extract_first(),\n",
        "                'minifigs': brickset.xpath(MINIFIGS_SELECTOR).extract_first(),\n",
        "                'image': brickset.css(IMAGE_SELECTOR).extract_first(),\n",
        "            }\n",
        "\n",
        "        NEXT_PAGE_SELECTOR = '.next a ::attr(href)'\n",
        "        next_page = response.css(NEXT_PAGE_SELECTOR).extract_first()\n",
        "        if next_page:\n",
        "            yield scrapy.Request(\n",
        "                response.urljoin(next_page),\n",
        "                callback=self.parse\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70g3ILK8vlwV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "process = CrawlerProcess({\n",
        "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
        "})\n",
        "\n",
        "process.crawl(BrickSetSpider)\n",
        "process.start() # the script will block here until the crawling is finished"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}